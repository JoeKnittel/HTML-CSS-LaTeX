% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Foundations of Casualty Actuarial Science Notes},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{actuarialsymbol}
\usepackage{actuarialangle}

\title{Foundations of Casualty Actuarial Science Notes}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

\(\newcommand{\vect}[1]{\boldsymbol{#1}}\)
\(\newcommand\given[1][]{\:#1\vert\:}\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(rmarkdown)}
\end{Highlighting}
\end{Shaded}

\hypertarget{useful-notation-and-formulas}{%
\section{Useful Notation and
Formulas}\label{useful-notation-and-formulas}}

\begin{red}

\[
  \Phi(x)= \text{N}(x)  =\Pr(Z \le x) \quad \text{ is the cumulative distribution for the unit normal}
\]

\end{red}

\hypertarget{introduction}{%
\section{1: Introduction}\label{introduction}}

\begin{itemize}
\tightlist
\item
  Credibility theory provides tools to deal with the randomness of data
  that is used for predicting future events or costs
\end{itemize}

\begin{purple}

\[
  \textbf{Credibility-Weighted Estimate: } \\ \quad \text{Estimate } = Z \times [\text{Observation}] + (1-Z) \times [\text{Other Information}], \quad 0 \leq Z \leq 1 \\
\]

\begin{itemize}
\item
  \(Z\) is called the \textbf{\emph{credibility}} and \(1-Z\) is
  generally referred to as the \textbf{\emph{complement of credibility}}
\item
  If the body of the observed data is large, \(Z\) will be close to
  \(1\)
\item
  \(\text{Other Information}\) represents an estimate or prior
  hypothesis of a rate to charge in the absence of the recent experience
\end{itemize}

\end{purple}

\hypertarget{classical-credibility}{%
\section{2: Classical Credibility}\label{classical-credibility}}

\hypertarget{introduction-1}{%
\subsection{2.1: Introduction}\label{introduction-1}}

\begin{blue}

\begin{itemize}
\item
  \textbf{\emph{Full Credibility Criterion}} (or, \textbf{\emph{Standard
  for Full Credibility}}) is the minimum amount of data in order to set
  \(Z=1\) in the credibility-weighted estimate above
\item
  If \(Z<1\), we have a case of \textbf{\emph{partial credibility}}
\end{itemize}

\end{blue}

\begin{green}

\hypertarget{basic-concepts-from-classical-credibility}{%
\subsubsection{Basic Concepts from Classical
Credibility}\label{basic-concepts-from-classical-credibility}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  How to determine the criterion for full credibility when estimating
  frequencies
\item
  How to determine the criterion for full credibility when estimating
  severities
\item
  How to determine the criterion for full credibility when estimating
  pure premiums
\item
  How to determine the amount of partial credibility to assign when one
  has less than that which is needed for full credibility
\end{enumerate}

\end{green}

\hypertarget{full-credibility-for-frequency}{%
\subsection{2.2: Full Credibility for
Frequency}\label{full-credibility-for-frequency}}

\begin{yellow}

\hypertarget{probability-that-a-poisson-distributed-variable-is-within-pm-k-of-the-mean}{%
\subsubsection{\texorpdfstring{Probability that a Poisson-distributed
Variable is Within \(\pm k\)\% of the
Mean:}{Probability that a Poisson-distributed Variable is Within \textbackslash pm k\% of the Mean:}}\label{probability-that-a-poisson-distributed-variable-is-within-pm-k-of-the-mean}}

\begin{itemize}
\item
  Consider a random variable \(X\sim \text{Pois}(n, \sqrt{n})\).
\item
  We can approximate \(X\) with a normally-distributed variable with the
  same mean and variance given there are enough expected claims:
  \(X' \sim \mathcal{N}(\mu = n, \sigma = \sqrt{n})\)
\item
  If we want to approximate the probability, \(P\), that observation
  \(X\) is within \(\pm k\) of the mean, we get:
\end{itemize}

\[
  \begin{align}
    P &= \Pr(\mu - k \mu\leq X \leq \mu + k \mu) \\
      &= \Pr(-k\mu/\sigma \leq Z \le k\mu/\sigma) \\
      &= \Pr(-k\sqrt{n} \le Z \le k\sqrt{n}) \\
      &= \Pr(Z \le k\sqrt{n}) - \Pr(Z \le -k\sqrt{n}) \\
      &= \Phi(k\sqrt{n}) - \Phi(-k\sqrt{n}) \\
      &= \Phi(k\sqrt{n}) - (1 - \Phi(k\sqrt{n})  \\
      &= 2\cdot \Phi(k\sqrt{n}) - 1
  \end{align}
\]

\includegraphics{Figures/1+.png}

\end{yellow}

\begin{orange}

\hypertarget{standard-for-full-credibility-of-a-poisson-distributed-variable}{%
\subsubsection{Standard for Full Credibility of a Poisson-distributed
Variable}\label{standard-for-full-credibility-of-a-poisson-distributed-variable}}

\begin{itemize}
\item
  We want to know how many claims, \(n\), are required for us to be able
  to say the observation is fully credible
\item
  If \(P\) and \(k\) are known (constraints on how precise we require
  our observations to be in order to lend credence), we can use our
  formula from above to calculate \(n=n_0\), the
  \(\text{Standard for Full Credibility}\) is calculated as follows:
\end{itemize}

\[
  \begin{align}
    P &= 2 \cdot \Phi(k\sqrt{n}) - 1 \\ \\
    \textbf{Standard for Full Credibility (Poisson): } \quad n_0 &= \left(\dfrac{\Phi^{-1}\left( \dfrac{P+1}{2} \right)}{k} \right)^2 =\dfrac{y^2}{k^2}, \quad \left(\text{where } y = \Phi^{-1}\left(\dfrac{P+1}{2}\right)\right) 
  \end{align}
\]

\includegraphics{Figures/2+.png}

\begin{itemize}
\item
  The value 1,082 claims \(\left(P=90\%, k=5\%\right)\) is commonly used
  in applications
\item
  Often \(\pm2\) standard deviations \((P=95\%)\) is used
\end{itemize}

\end{orange}

\begin{red}

\hypertarget{variations-from-the-poisson-assumptions}{%
\subsubsection{Variations from the Poisson
Assumptions}\label{variations-from-the-poisson-assumptions}}

\begin{itemize}
\item
  Occasionally, we will want to use a Binomial or Negative Binomial
  distribution rather than a Poisson distribution to estimate
  frequencies. This changes things, because, for these other
  distributions, the mean does not equal the variance
\item
  We can derive a generalized formula for the
  \(\text{Standard for Full Credibility}\) as follows:
\end{itemize}

\[
  \textbf{Standard for Full Credibility (Generalized): }  \quad n_0 = c \cdot \dfrac{y^2}{k^2}, \quad \quad \left(\text{where } c = \dfrac{\sigma_f^2}{\mu_f} \right)
\]

\begin{itemize}
\tightlist
\item
  \emph{Note: \(c=1\) in the Poisson case, \(c=1-q\) in the Binomial
  case, \(c=1+\beta\) in the Negative Binomial case}
\end{itemize}

\end{red}

\begin{purple}

\hypertarget{exposures-vs.-claims}{%
\subsubsection{Exposures vs.~Claims}\label{exposures-vs.-claims}}

\begin{itemize}
\item
  \(\text{Standards for Full Credibility}\) are calculated in terms of
  the expected number of claims
\item
  It is common to translate these into a number of exposures by dividing
  by the (appoximate) expected claim frequency (e.g.,
  \(n_0 = 1082 (P=90\%, k=5\%)\) and expected claim frequency is
  \(0.04\) claims per house-year; hence, the
  \(\text{Standard for Full Credibility}\) would be
  \(1082/0.04\simeq 27,000\) house-years)
\item
  See \textbf{\emph{Example 2.2.3}} on p.~11 for a demonstration of
  exposures and variation from Poisson assumptions
\end{itemize}

\end{purple}

\hypertarget{full-credibility-for-severity}{%
\subsection{2.3: Full Credibility for
Severity}\label{full-credibility-for-severity}}

\begin{blue}

\hypertarget{probability-p-that-the-observed-severity-s-is-pm-k-of-the-mean}{%
\subsubsection{\texorpdfstring{Probability, \(P\), that the Observed
Severity, \(S\), is \(\pm k\%\) of the
Mean}{Probability, P, that the Observed Severity, S, is \textbackslash pm k\textbackslash\% of the Mean}}\label{probability-p-that-the-observed-severity-s-is-pm-k-of-the-mean}}

\begin{itemize}
\item
  The Classical Credibility ideas can also be applied to estimating
  claim severity, the average size of a claim
\item
  Suppose a sample of \(n\) claims, \(x_1,x_2,\dots,x_n\) are each
  independently drawn from a loss distribution with mean, \(\mu_s\), and
  variance, \(\sigma_s^2\)
\item
  The observation mean of \(S\):
  \(\dfrac{x_1+x_2+\dots+x_n}{n} \simeq \mu_S\)
\item
  The observation standard deviation of \(S\):
  \(\dfrac{\sigma_S}{\sqrt{n}}\)
\item
  Hence, the probability that \(S\) is within \(\pm k\%\) of its mean
  can be determined as follows:
\end{itemize}

\[
  \begin{align}
    P &= \Pr(\mu_S-k\mu_S \le S \le \mu_S + k\mu_S) \\
      &= \Pr(-k\sqrt{n} \cdot (\mu_S/\sigma_S) \le Z \le k\sqrt{n} \cdot (\mu_S/\sigma_S) \\
      &= \Pr(Z \le k\sqrt{n} \cdot (\mu_S/\sigma_S)) - (1 - \Pr(Z \le k\sqrt{n} \cdot (\mu_S/\sigma_S))) \\
      &= 2 \cdot \Phi(k\sqrt{n} \cdot (\mu_S/\sigma_S)) - 1
  \end{align}
\]

\end{blue}

\begin{green}

\hypertarget{standard-for-full-credibility-for-severity}{%
\subsubsection{Standard for Full Credibility for
Severity}\label{standard-for-full-credibility-for-severity}}

\begin{itemize}
\tightlist
\item
  In order to find the \(\text{Standard for Full Credibility}\), we
  proceed as we had done for that of frequencies (i.e., by solving the
  above equation for \(n\)):
\end{itemize}

\[
  \begin{align}   
    P &= 2 \cdot \Phi(k\sqrt{n} \cdot (\mu_s/\sigma_s)) - 1 \\  \\
    \therefore n &= \left(\dfrac{\Phi^{-1}\left( \dfrac{P+1}{2} \right)}{k} \right)^2 \cdot\left( \dfrac{\sigma_S}{\mu_S} \right)^2 \\ \\
  \end{align}
\] \[
  \textbf{Standard for Full Credibility for Severity: } \quad     n = n_0 \cdot CV_S^2
\]

\begin{itemize}
\tightlist
\item
  \emph{Note: \(n_0\) is the \(\text{Standard for Full Credibility}\)
  for Frequency given \(P\) and \(k\), and the}
  \textbf{\emph{coefficient of variation}}
  \emph{\(CV_S \equiv \dfrac{\sigma_S}{\mu_S}\)}
\end{itemize}

\end{green}

\hypertarget{process-variance-of-l-pp-and-lr}{%
\subsection{2.4: Process Variance of L, PP, and
LR}\label{process-variance-of-l-pp-and-lr}}

\begin{itemize}
\tightlist
\item
  Suppose that \(n\) claims of size \(x_1,x_2,\dots,x_n\) occur during
  the observation period
\end{itemize}

\begin{yellow}

\hypertarget{useful-quantities}{%
\subsubsection{Useful Quantities}\label{useful-quantities}}

\[
  \begin{align}
    \textbf{Aggregate Losses: } \quad L &= x_1+x_2+\dots+x_n \\ \\
    \textbf{Pure Premium: } \quad PP &= \dfrac{x_1+x_2+\dots+x_n}{\text{exposures}} = \dfrac{L}{\text{exposures}} = \text{frequency} \times \text{severity} \\ \\
    \textbf{Loss Ratio: } \quad LR &= \dfrac{x_1+x_2+\dots+x_n}{\text{earned premium}}
  \end{align}
\]

\end{yellow}

\begin{orange}

\hypertarget{process-variance-of-l-pp-or-lr}{%
\subsubsection{Process Variance (of L, PP, or
LR)}\label{process-variance-of-l-pp-or-lr}}

The variance of the observed pure premiums (or aggregate losses or loss
ratio) for a given risk that occurs due to random fluctuations is
referred to as the \textbf{\emph{process variance}}

Let
\(\blacksquare = \text{pure premium|aggregate losses|loss ratio} = \text{PP|L|LR}\)

\hypertarget{frequency-and-severity-not-independent}{%
\paragraph{Frequency and Severity not
Independent}\label{frequency-and-severity-not-independent}}

\[
  \textbf{Process Variance of  } \ \blacksquare \text{ : } \quad \sigma_{\blacksquare}^2 = \text{E}(\blacksquare^2) - \text{E}(\blacksquare)^2 
\]

\begin{itemize}
\tightlist
\item
  See \textbf{\emph{Example 2.4.1}}
\end{itemize}

\hypertarget{frequency-and-severity-are-independent}{%
\paragraph{Frequency and Severity are
Independent}\label{frequency-and-severity-are-independent}}

\[
  \begin{align}
    \textbf{Process Variance of } \ \blacksquare \text{: } \quad \sigma_{\blacksquare}^2 &= \mu_f \cdot \sigma_S^2 + \mu_S^2 \cdot \sigma_f^2 \\
    &= \mu_f \cdot  \text{E}(S^2)  \quad \quad \ \ \ \text{(Poisson frequency)}
  \end{align}
\]

\hypertarget{normal-approximation-and-textstandard-for-full-credibility-for-textltextpptextlr}{%
\paragraph{\texorpdfstring{Normal Approximation and
\(\text{Standard for Full Credibility}\) for
\(\text{L}\)/\(\text{PP}\)/\(\text{LR}\)}{Normal Approximation and \textbackslash text\{Standard for Full Credibility\} for \textbackslash text\{L\}/\textbackslash text\{PP\}/\textbackslash text\{LR\}}}\label{normal-approximation-and-textstandard-for-full-credibility-for-textltextpptextlr}}

\begin{itemize}
\item
  For large numbers of expected claims, the observed \(\blacksquare\)
  are approximately normally distributed
\item
  With this assumption, we can construct confidence intervals (e.g.,
  there's a 95\% chance \(\blacksquare\) is within \(\pm 10\%\) of its
  expected value)
\item
  Flipping the previous statement, we can determine Standards for Full
  Credibility for \(\blacksquare\) (e.g., 3,645 claims are needed in
  order to have a 95\% chance that \(\blacksquare\) will be within
  \(\pm 10\%\) of its expected value) using the same strategy as
  described in Section 2.2 and Section 2.3. This process is described in
  Section 2.5
\end{itemize}

\end{orange}

\hypertarget{full-credibility-for-textl-textpp-and-textlr}{%
\subsection{\texorpdfstring{2.5: Full Credibility for \(\text{L}\),
\(\text{PP}\), and
\(\text{LR}\)}{2.5: Full Credibility for \textbackslash text\{L\}, \textbackslash text\{PP\}, and \textbackslash text\{LR\}}}\label{full-credibility-for-textl-textpp-and-textlr}}

\begin{itemize}
\tightlist
\item
  Because they are more difficult to estimate than frequencies, all
  other things being equal, the Standard for Full Credibility is larger
  for \(\blacksquare\) than for frequencies
\end{itemize}

\begin{red}

\hypertarget{probability-p-that-blacksquare-is-pm-k-of-the-mean}{%
\subsubsection{\texorpdfstring{Probability, \(P\), that \(\blacksquare\)
is \(\pm k\%\) of the
Mean}{Probability, P, that \textbackslash blacksquare is \textbackslash pm k\textbackslash\% of the Mean}}\label{probability-p-that-blacksquare-is-pm-k-of-the-mean}}

Assuming the Normal Approximation, we have:

\[
  \begin{align}
  P &= \Pr(\mu_{\blacksquare} - k \mu_{\blacksquare} \le \blacksquare \le \mu_{\blacksquare} + k \mu_{\blacksquare}) \\
    &= \Pr(-k(\mu_{\blacksquare}/\sigma_{\blacksquare}) \le Z \le k(\mu_{\blacksquare}/\sigma_{\blacksquare})) \\
    &= 2 \cdot \Phi(k (\mu_\blacksquare/\sigma_\blacksquare)) - 1 \\ \\
  \therefore y &= k(\mu_\blacksquare/\sigma_\blacksquare) \quad \left(\text{where } y = \Phi^{-1}\left(\dfrac{P+1}{2}\right)\right)
  \end{align}
\]

\end{red}

\begin{purple}

\hypertarget{standard-for-full-credibility-of-blacksquare}{%
\subsubsection{\texorpdfstring{Standard for Full Credibility of
\(\blacksquare\)}{Standard for Full Credibility of \textbackslash blacksquare}}\label{standard-for-full-credibility-of-blacksquare}}

Now, \textbf{\emph{assume that the frequency has a Poisson
distribution}}

Let \(n_F\) be the expected number of claims for Full Credibility of
\(\blacksquare\).

Then, \(\mu_f = \sigma_f^2 = n_F\). Additionally,

\[
  \begin{align}
    \mu_\blacksquare &= \mu_f \cdot \mu_S = n_F \cdot \mu_S \\
    \sigma_\blacksquare^2 &= \mu_f(\sigma_S^2 + \mu_S^2) = n_F(\sigma_S^2 + \mu_S^2)
  \end{align}
\] Hence, we have:

\[
    y = k(\mu_\blacksquare/\sigma_\blacksquare) = k\left(\dfrac{n_F \cdot \mu_S}{\sqrt{n_F(\sigma_S^2 + \mu_S^2)}}\right)  
\]

\[
  \begin{align}
    \textbf{Standard for Full Credibility of } \ \blacksquare \textbf{ (Poisson) :} \quad \ n_F &= \dfrac{y^2}{k^2}\left(1+ \dfrac{\sigma_S^2}{\mu_S^2} \right) = n_0\left( 1 + CV_S^2 \right) \\ \\
    &= \text{Standard for Full Credibility of Frequency} \\
    & \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad + \\
    & \text{ } \quad \text{Standard for Full Credibility of Severity}
  \end{align}
\]

\emph{Note: \(n_0 = \dfrac{y^2}{k^2}\) is the Standard for Full
Credibility of Frequency and \(CV_S = \dfrac{\sigma_S}{\mu_S}\) is the
coefficient of variation of the severity as defined in previous
sections}

\end{purple}

\begin{blue}

\hypertarget{variations-from-the-poisson-assumption}{%
\paragraph{Variations from the Poisson
Assumption}\label{variations-from-the-poisson-assumption}}

\begin{itemize}
\tightlist
\item
  A more general formula for when the Poisson assumption does not apply:
\end{itemize}

\[
  \textbf{Standard for Full Credibility of } \  \blacksquare \text{ (Generalized): } \quad n_F = \dfrac{y^2}{k^2}\left( \dfrac{\sigma_f^2}{\mu_f} + \dfrac{\sigma_S^2}{\mu_S^2} \right) = n_0 \left( \dfrac{\sigma_f^2}{\mu_f} + CV_S^2  \right)
\]

\end{blue}

\hypertarget{partial-credibility}{%
\subsection{2.6: Partial Credibility}\label{partial-credibility}}

\begin{itemize}
\tightlist
\item
  We've defined it to be the case that if the Standard for Full
  Credibility is met, \(Z\equiv 1\), but how do we define \(Z\) for
  partial credibility (i.e., if the Standard for Full Credibility is not
  met)?
\end{itemize}

\begin{green}

Let \(n_F\) be the Standard for Full Credibility for either frequency,
severity, or pure premiums. Then, we can defined the credibility, \(Z\),
as follows:

\[
  \textbf{Credibility: } \quad Z = \begin{cases}
        1, & n \ge n_F \\
        \sqrt{\dfrac{n}{n_F}},    & n < n_F
      \end{cases}
\]

\end{green}

\hypertarget{least-squares-credibility}{%
\section{3: Least Squares Credibility}\label{least-squares-credibility}}

\begin{itemize}
\item
  \textbf{\emph{Least Squares Credibility}} = \textbf{\emph{Bühlmann
  Credibility}} = \textbf{\emph{Greatest Accuracy Credibility}}
\item
  \(Z = n/(n+k)\)
\item
  Bühlmann Credibility Parameter: \(k\)
\end{itemize}

\hypertarget{analysis-of-variance}{%
\subsection{3.1: Analysis of Variance}\label{analysis-of-variance}}

\begin{yellow}

\[
  \textbf{Expected Value of the Process Variance (EPV): } \\ \text{E}_\theta\left[\text{Var}\left[X|\theta\right]\right] = \sum_{j} \Pr(\theta_j) \cdot \text{Var}[X|\theta_j]
\]

\begin{itemize}
\item
  \(\text{EPV}\) is a weighted sum of the process variances for each
  type of risk
\item
  \(\theta_j\) might represent the types of dice (e.g., \(\theta_1\) = a
  6-sided die)
\end{itemize}

\end{yellow}

\begin{yellow}

\[
  \textbf{Variance of the Hypothetical Means (VHM): } \\ \text{Var}_\theta\left[\text{E}\left[X|\theta\right]\right] = \sum_{j} \Pr(\theta_j) \cdot \text{E}[X|\theta_j]^2 - \left( \sum_{j} \Pr(\theta_j) \cdot \text{E}[X|\theta_j] \right)^2
\]

\end{yellow}

\begin{yellow}

\[
  \textbf{Total Variance} = \text{Var}[X] =\text{E}_\theta\left[\text{Var}\left[X|\theta\right]\right] + \text{Var}_\theta\left[\text{E}\left[X|\theta\right]\right] = \text{EPV} + \text{VHM}
\]

\end{yellow}

\begin{itemize}
\tightlist
\item
  \textbf{\emph{A Series of Examples}} from p.43-48 is very insightful!
\end{itemize}

\hypertarget{buxfchlmann-credibility}{%
\subsection{3.2: Bühlmann Credibility}\label{buxfchlmann-credibility}}

\begin{orange}

\[
  \begin{align}
    \textbf{Bühlmann Credibility Parameter: }& \quad k = \dfrac{\text{EPV}}{\text{VHM}} \\ \\
    \textbf{Bühlmann Credibility: }& \quad Z = \dfrac{n}{n+k}, \quad \text{(for } n \text{ observations)} \\ \\
      & \quad \ \ \ \ = \dfrac{\text{VHM}}{\text{Total Variance}}, \quad \text{(if } n=1)  
  \end{align}
\]

\begin{itemize}
\item
  \emph{\(\lim_\limits{n \to \infty} Z =1\)}
\item
  Compute \(\text{EPV}\) and \(\text{VHM}\) for a single observation,
  then plug into the formula for \(\text{Bühlmann Credibility}\) with
  \(n\) being the amount of observations
\item
  If estimating claim frequencies or pure premiums, then \(n\) is in
  exposures
\item
  If estimating claim severities, then \(n\) is in number of claims
\item
  In general,
  \(\text{Estimate(PP)} \ne \text{Estimate(Frequency)} \cdot \text{Estimate(Severity)}\)
\item
  \textbf{\emph{A Series of Examples}} on p.~57-59 is insightful
\end{itemize}

\end{orange}

\hypertarget{assumptions-underlying-z-nnk}{%
\subsubsection{\texorpdfstring{Assumptions Underlying
\(Z = n/(n+k)\)}{Assumptions Underlying Z = n/(n+k)}}\label{assumptions-underlying-z-nnk}}

\begin{red}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The complement of credibility is given to the overall mean
\item
  The credibility is determined as the slope of the weighted least
  squares line to the Bayesian Estimates
\item
  The risk parameters and risk process do not shift over times
\item
  The expected value of the process variance of the sum of \(n\)
  observations increases as \(n\). Therefore, the expected value of the
  process variance of the average of \(n\) observations decreases as
  \(1/n\)
\item
  The variance of the hypothetical means of the sum of \(n\)
  observations increases as \(n^2\). Therefore, the variance of the
  hypothetical means of the average of \(n\) observations is independent
  of \(n\)
\end{enumerate}

\end{red}

\hypertarget{target-shooting-example}{%
\subsection{3.3: Target Shooting
Example}\label{target-shooting-example}}

\begin{purple}

\begin{itemize}
\item
  The average spread over the marksmen is the \(\text{EPV}\)
\item
  The spread of the targets can be quantified as the \(\text{VHM}\)
\item
  The number of shots we observe from the \emph{same} unknown marksman
  is \(n\)
\end{itemize}

\includegraphics{Figures/5+.png}

\end{purple}

\begin{itemize}
\item
  In general, the \(\text{Bühlmann Credibility}\) is a relative measure
  of the value of the information contained in the observation versus
  that in the a priori mean
\item
  In most applications of \(\text{Bühlmann Credibility}\), the
  \(\text{EPV}>0\) and \(\text{VHM}<\infty\); hence, \(k>0\)
\item
  In ordinary circumstances, \(0<\text{Bühlmann Credibility}<1\)
\end{itemize}

\hypertarget{bayesian-analysis}{%
\section{4: Bayesian Analysis}\label{bayesian-analysis}}

\begin{blue}

\begin{itemize}
\item
  \(\text{Bayesian Analysis}\) is another technique to update a prior
  hypothesis based on observations, closely related to the use of
  \(\text{Bühlmann Credibility}\)
\item
  \(\text{Bühlmann Credibility}\) is the least squares linear
  approximation to \(\text{Bayesian Analysis}\)
\end{itemize}

\end{blue}

\hypertarget{mathematical-preliminaries}{%
\subsection{4.1: Mathematical
Preliminaries}\label{mathematical-preliminaries}}

\begin{green}

\hypertarget{useful-definitions}{%
\subsubsection{Useful Definitions}\label{useful-definitions}}

\[
  \begin{align}
  \textbf{Conditional Probability: }& \quad\text{P}(A \given B) =  \dfrac{\text{P}(A \cap B)}{\text{P}(B)} \\ \\
  \textbf{Marginal Distribution Function: }& \quad \text{P}(B)  = \sum_i \ \text{P}(B \cap A_i) = \sum_i \ \text{P}(B \given A_i) \cdot \text{P}(A_i) \quad (\text{if }A_i \text{ disjoint})\\ \\
  \textbf{Conditional Distributions: } & \quad \text{P}(B \given A_i) \\ \\
  \textbf{Probabilities: } & \quad \text{P}(A_i) \\ \\
  \textbf{Posterior Probabilities: }& \quad \text{P}(\theta_i\given X = x)
  \end{align}
\]

\end{green}

\begin{yellow}

\hypertarget{conditional-expectation}{%
\subsubsection{Conditional Expectation}\label{conditional-expectation}}

In general, in order to compute a conditional expectation, we take the
weighted average over all the possibilities, \(x\):

\[
  \text{E}(X \given B) = \sum_x \ x \cdot \text{P}(X = x \given B)
\]

\end{yellow}

\hypertarget{bayesian-analysis-1}{%
\subsection{4.2: Bayesian Analysis}\label{bayesian-analysis-1}}

\begin{orange}

\[
  \begin{align}
    \textbf{Bayes' Theorem: } \quad \text{P}(A_i \given B) &= \dfrac{\text{P}(B \given A_i) \cdot         \text{P}(A_i)}{\text{P}(B)} = \dfrac{\text{P}(B \given A_i) \cdot \text{P}(A_i)}{\sum_\limits j \text{P}(B \given A_j) \cdot \text{P}(A_j)} \\ \\
    \text{P}(A \given B) &= \dfrac{\text{P}(B \given A) \cdot \text{P}(A)}{\text{P}(B)}
  \end{align}
\] \(A_i\) represents a partition of \(A\) (one of \(A\)'s disjoint
subsets)

\end{orange}

\begin{red}

\hypertarget{posterior-estimates}{%
\subsubsection{Posterior Estimates}\label{posterior-estimates}}

\[
  \textbf{Posterior Estimate: } \quad \text{E}(X \given X = x) =\sum_i \ \text{P}(\theta_i \given X=x) \cdot \text{E}(X  \given \theta_i)
\]

\begin{itemize}
\item
  The \(\text{Posterior Estimate}\) is sometimes called the
  \(\text{Bayesian Estimate}\) or the
  \(\text{Bayesian Posterior Estimate}\)
\item
  The result of \(\text{Bayesian Analysis}\) (i.e., the
  \(\text{Posterior Estimate}\)) is always within the range of
  hypotheses

  \begin{itemize}
  \tightlist
  \item
    e.g.,
    \(\text{P}(X \given \theta_1) = 0.3; \text{P}(X \given \theta_2) = 0.5\)
    \(\rightarrow 0.3\le \text{E}(\text{P}(X) \given obs) \le 0.5\)
  \end{itemize}
\end{itemize}

\end{red}

\begin{red}

\[
  \textbf{A Priori Mean: } \quad \text{E}(X) = \sum_i \  \text{P}(X = x_i) \cdot \text{E}(X \given X = x_i)
\]

\begin{itemize}
\item
  The sum of the product of the a priori chance of each outcome times
  its \(\text{Posterior Estimate}\) is equal to the a prior mean

  \begin{itemize}
  \tightlist
  \item
    This is referred to as ``the estimates being in balance''
  \end{itemize}
\end{itemize}

\end{red}

\hypertarget{relation-of-bayesian-analysis-and-buxfchlmann-credibility}{%
\subsubsection{Relation of Bayesian Analysis and Bühlmann
Credibility}\label{relation-of-bayesian-analysis-and-buxfchlmann-credibility}}

\begin{itemize}
\tightlist
\item
  The \(\text{Bühlmann Credibility Estimates}\) are the weighted least
  squares line fit to the \(\text{Bayesian Estimates}\):
\end{itemize}

\includegraphics{Figures/6+.png}

\begin{purple}

\includegraphics{Figures/7+.png}

\end{purple}

\hypertarget{continuous-prior-and-posterior-distributions}{%
\subsection{4.3: Continuous Prior and Posterior
Distributions}\label{continuous-prior-and-posterior-distributions}}

\begin{blue}

Let \(X\) and \(Y\) be two random variables. Then,

\[
  \begin{align}
    \textbf{Joint p.d.f: }& \quad f(x,y) \\ \\
    \textbf{Marginal p.d.f's: }& \quad f_X (x) = \int_{-\infty}^\infty f(x,y) \ dy  \\ \\
    \textbf{Conditional p.d.f for } X \textbf{ given } Y \textbf{: }& \quad f_X(x \given y) = \dfrac{f(x,y)}{f_Y(y)} \\ \\
  \end{align}
\]

\end{blue}

\begin{green}

In insurance applications, it is common for there to be two variables of
interest, with one being discrete and the other being continuous. Let
\(X\) be discrete (it may represent number of claims) and \(\theta\) be
a parameter of the distribution of \(X\). Then,

\[
  f(x,\theta) = f_X(x \given \theta) \cdot f_\Theta(\theta)
\]

\begin{itemize}
\tightlist
\item
  \(f_\theta(\theta)\) is the \textbf{\emph{prior distribution}} of
  \(\theta\) (it's the marginal p.d.f of \(\Theta\)). It may represent
  our initial guess about the distribution of some characteristic within
  a population (e.g., expected claim frequency)
\end{itemize}

\end{green}

\begin{green}

Combining the preceeding joing p.d.f equation with the conditional p.d.f
equation from the sub-section above, we have:

\[
  f_\Theta(\theta \given x) = \dfrac{f_X(x \given \theta) \cdot f_\Theta(\theta)}{f_X(x)}
\]

\begin{itemize}
\tightlist
\item
  \(f_\Theta(\theta \given x)\) is the \textbf{\emph{posterior
  distribution}} of \(\Theta\) for the selected risk (i.e., for
  \(X = x\))
\end{itemize}

\end{green}

\begin{yellow}

\[
  \textbf{Conditional Expectation: } \quad \text{E}(X \given Y) = \int_{-\infty}^\infty \ x \cdot f_X(x \given y) \ dx
\]

\end{yellow}

\begin{yellow}

\[
  \textbf{Expectation of } X \textbf{: } \quad \text{E}(X) = \text{E}_Y(\text{E}_X(X \given Y)) = \int_{-\infty}^\infty \left[ \int_{-\infty}^\infty  \ x \cdot f_X(x \given y) \ dx \right] \cdot f_Y(y) \ dy
\]

\end{yellow}

\begin{itemize}
\tightlist
\item
  Review \textbf{\emph{Examples 4.3.1-3}}
\end{itemize}

\hypertarget{conjugate-priors}{%
\section{5: Conjugate Priors}\label{conjugate-priors}}

\hypertarget{gamma-function-and-distribution}{%
\subsection{5.1: Gamma Function and
Distribution}\label{gamma-function-and-distribution}}

\hypertarget{the-gamma-poisson-model}{%
\subsection{5.2: The Gamma-Poisson
Model}\label{the-gamma-poisson-model}}

\hypertarget{bayesian-analysis-on-the-gamma-poisson-model}{%
\subsection{5.3: Bayesian Analysis on the Gamma-Poisson
Model}\label{bayesian-analysis-on-the-gamma-poisson-model}}

\hypertarget{buxfchlmann-credibility-in-the-gamma-poisson-model}{%
\subsection{5.4: Bühlmann Credibility in the Gamma-Poisson
Model}\label{buxfchlmann-credibility-in-the-gamma-poisson-model}}

\end{document}
